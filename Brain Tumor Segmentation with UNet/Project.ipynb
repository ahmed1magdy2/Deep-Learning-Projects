{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda31c30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T18:45:49.986013Z",
     "start_time": "2023-10-28T18:45:49.981925Z"
    }
   },
   "source": [
    "# import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224831bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T21:54:01.985761Z",
     "start_time": "2023-12-07T21:53:57.044896Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from unet import build_unet\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "from sklearn.metrics import f1_score, jaccard_score, precision_score, recall_score\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d863601a",
   "metadata": {},
   "source": [
    "#  Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d04afc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T21:54:02.006516Z",
     "start_time": "2023-12-07T21:54:01.988585Z"
    }
   },
   "outputs": [],
   "source": [
    "H = 256\n",
    "W = 256\n",
    "model_name = \"model_segmentation_256px.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01422b7a",
   "metadata": {},
   "source": [
    "# define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aa74cdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T21:54:02.037720Z",
     "start_time": "2023-12-07T21:54:02.009085Z"
    }
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=100):        \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return dice\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def load_dataset(path, split=0.2):\n",
    "    images = sorted(glob(os.path.join(path, \"images\", \"*.png\")))\n",
    "    masks = sorted(glob(os.path.join(path, \"masks\", \"*.png\")))\n",
    "\n",
    "    split_size = int(len(images) * split)\n",
    "\n",
    "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
    "    train_y, valid_y = train_test_split(masks, test_size=split_size, random_state=42)\n",
    "\n",
    "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "    train_y, test_y = train_test_split(train_y, test_size=split_size, random_state=42)\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (W, H))\n",
    "    x = x / 255.0\n",
    "    x = x.astype(np.float32)\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (h, w)\n",
    "    x = cv2.resize(x, (W, H))   ## (h, w)\n",
    "    x = x / 255.0               ## (h, w)\n",
    "    x = x.astype(np.float32)    ## (h, w)\n",
    "    x = np.expand_dims(x, axis=-1)## (h, w, 1)\n",
    "    return x\n",
    "\n",
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
    "    x.set_shape([H, W, 3])\n",
    "    y.set_shape([H, W, 1])\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(X, Y, batch=2):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.prefetch(10)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def save_results(image, mask, y_pred, save_image_path):\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)\n",
    "\n",
    "    y_pred = np.expand_dims(y_pred, axis=-1)\n",
    "    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1)\n",
    "    y_pred = y_pred * 255\n",
    "\n",
    "    line = np.ones((H, 10, 3)) * 255\n",
    "\n",
    "    cat_images = np.concatenate([image, line, mask, line, y_pred], axis=1)\n",
    "    cv2.imwrite(save_image_path, cat_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0534ba93",
   "metadata": {},
   "source": [
    "# Directory for storing files and set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a0bb345",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T21:54:02.052896Z",
     "start_time": "2023-12-07T21:54:02.038359Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "create_dir(\"files\")\n",
    "\n",
    "batch_size = 16\n",
    "lr = 1e-4\n",
    "num_epochs = 100\n",
    "model_path = os.path.join(\"files\", model_name)\n",
    "csv_path = os.path.join(\"files\", \"log.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7935356f",
   "metadata": {},
   "source": [
    "# load a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "986c8544",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T21:54:02.270695Z",
     "start_time": "2023-12-07T21:54:02.054908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1840 - 1840\n",
      "Valid: 612 - 612\n",
      "Test : 612 - 612\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"Dataset/\"\n",
    "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
    "\n",
    "print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
    "print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
    "print(f\"Test : {len(test_x)} - {len(test_y)}\")\n",
    "\n",
    "train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0801e6",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9be9622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T21:54:03.366028Z",
     "start_time": "2023-12-07T21:54:02.272718Z"
    }
   },
   "outputs": [],
   "source": [
    "model = build_unet((H, W, 3))\n",
    "model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "    CSVLogger(csv_path),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False), # edit the (patience = 10 , restore = True) \n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c33b1",
   "metadata": {},
   "source": [
    "**Train the `model`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d7c4a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:08:32.462698Z",
     "start_time": "2023-12-07T21:54:03.368027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.8376 - dice_coef: 0.1624 \n",
      "Epoch 1: val_loss improved from inf to 0.97269, saving model to files\\model_segmentation_256px.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AI\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 4869s 42s/step - loss: 0.8376 - dice_coef: 0.1624 - val_loss: 0.9727 - val_dice_coef: 0.0273 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.6956 - dice_coef: 0.3044 \n",
      "Epoch 2: val_loss did not improve from 0.97269\n",
      "115/115 [==============================] - 4842s 42s/step - loss: 0.6956 - dice_coef: 0.3044 - val_loss: 0.9842 - val_dice_coef: 0.0158 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.5975 - dice_coef: 0.4025 \n",
      "Epoch 3: val_loss improved from 0.97269 to 0.96293, saving model to files\\model_segmentation_256px.h5\n",
      "115/115 [==============================] - 4848s 42s/step - loss: 0.5975 - dice_coef: 0.4025 - val_loss: 0.9629 - val_dice_coef: 0.0369 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.5204 - dice_coef: 0.4796 \n",
      "Epoch 4: val_loss improved from 0.96293 to 0.78570, saving model to files\\model_segmentation_256px.h5\n",
      "115/115 [==============================] - 4859s 42s/step - loss: 0.5204 - dice_coef: 0.4796 - val_loss: 0.7857 - val_dice_coef: 0.2138 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4374 - dice_coef: 0.5626 \n",
      "Epoch 5: val_loss improved from 0.78570 to 0.66991, saving model to files\\model_segmentation_256px.h5\n",
      "115/115 [==============================] - 4853s 42s/step - loss: 0.4374 - dice_coef: 0.5626 - val_loss: 0.6699 - val_dice_coef: 0.3262 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3781 - dice_coef: 0.6219 \n",
      "Epoch 6: val_loss improved from 0.66991 to 0.49112, saving model to files\\model_segmentation_256px.h5\n",
      "115/115 [==============================] - 4860s 42s/step - loss: 0.3781 - dice_coef: 0.6219 - val_loss: 0.4911 - val_dice_coef: 0.5033 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3307 - dice_coef: 0.6693 \n",
      "Epoch 7: val_loss improved from 0.49112 to 0.38297, saving model to files\\model_segmentation_256px.h5\n",
      "115/115 [==============================] - 4857s 42s/step - loss: 0.3307 - dice_coef: 0.6693 - val_loss: 0.3830 - val_dice_coef: 0.6163 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2924 - dice_coef: 0.7076 \n",
      "Epoch 8: val_loss improved from 0.38297 to 0.37460, saving model to files\\model_segmentation_256px.h5\n",
      "115/115 [==============================] - 4851s 42s/step - loss: 0.2924 - dice_coef: 0.7076 - val_loss: 0.3746 - val_dice_coef: 0.6254 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2658 - dice_coef: 0.7342 \n",
      "Epoch 9: val_loss improved from 0.37460 to 0.35034, saving model to files\\model_segmentation_256px.h5\n",
      "115/115 [==============================] - 4856s 42s/step - loss: 0.2658 - dice_coef: 0.7342 - val_loss: 0.3503 - val_dice_coef: 0.6494 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2406 - dice_coef: 0.7594 \n",
      "Epoch 10: val_loss improved from 0.35034 to 0.34379, saving model to files\\model_segmentation_256px.h5\n",
      "115/115 [==============================] - 4862s 42s/step - loss: 0.2406 - dice_coef: 0.7594 - val_loss: 0.3438 - val_dice_coef: 0.6565 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2296 - dice_coef: 0.7704 \n",
      "Epoch 11: val_loss improved from 0.34379 to 0.30027, saving model to files\\model_segmentation_256px.h5\n",
      "115/115 [==============================] - 4854s 42s/step - loss: 0.2296 - dice_coef: 0.7704 - val_loss: 0.3003 - val_dice_coef: 0.6998 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2089 - dice_coef: 0.7911 \n",
      "Epoch 12: val_loss improved from 0.30027 to 0.28006, saving model to files\\model_segmentation_256px.h5\n",
      "115/115 [==============================] - 4853s 42s/step - loss: 0.2089 - dice_coef: 0.7911 - val_loss: 0.2801 - val_dice_coef: 0.7176 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2037 - dice_coef: 0.7963 \n",
      "Epoch 13: val_loss did not improve from 0.28006\n",
      "115/115 [==============================] - 4857s 42s/step - loss: 0.2037 - dice_coef: 0.7963 - val_loss: 0.2924 - val_dice_coef: 0.7067 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1784 - dice_coef: 0.8216 \n",
      "Epoch 14: val_loss did not improve from 0.28006\n",
      "115/115 [==============================] - 4855s 42s/step - loss: 0.1784 - dice_coef: 0.8216 - val_loss: 0.2829 - val_dice_coef: 0.7174 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1645 - dice_coef: 0.8355 \n",
      "Epoch 15: val_loss improved from 0.28006 to 0.24567, saving model to files\\model_segmentation_256px.h5\n",
      "115/115 [==============================] - 4860s 42s/step - loss: 0.1645 - dice_coef: 0.8355 - val_loss: 0.2457 - val_dice_coef: 0.7535 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1526 - dice_coef: 0.8474 \n",
      "Epoch 16: val_loss improved from 0.24567 to 0.21240, saving model to files\\model_segmentation_256px.h5\n",
      "115/115 [==============================] - 4856s 42s/step - loss: 0.1526 - dice_coef: 0.8474 - val_loss: 0.2124 - val_dice_coef: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1421 - dice_coef: 0.8579 \n",
      "Epoch 17: val_loss did not improve from 0.21240\n",
      "115/115 [==============================] - 4853s 42s/step - loss: 0.1421 - dice_coef: 0.8579 - val_loss: 0.2145 - val_dice_coef: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1402 - dice_coef: 0.8598 \n",
      "Epoch 18: val_loss did not improve from 0.21240\n",
      "115/115 [==============================] - 4852s 42s/step - loss: 0.1402 - dice_coef: 0.8598 - val_loss: 0.2443 - val_dice_coef: 0.7510 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1336 - dice_coef: 0.8664 \n",
      "Epoch 19: val_loss did not improve from 0.21240\n",
      "115/115 [==============================] - 4844s 42s/step - loss: 0.1336 - dice_coef: 0.8664 - val_loss: 0.2443 - val_dice_coef: 0.7549 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1274 - dice_coef: 0.8726 \n",
      "Epoch 20: val_loss improved from 0.21240 to 0.20194, saving model to files\\model_segmentation_256px.h5\n",
      "115/115 [==============================] - 4849s 42s/step - loss: 0.1274 - dice_coef: 0.8726 - val_loss: 0.2019 - val_dice_coef: 0.7980 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1181 - dice_coef: 0.8819 \n",
      "Epoch 21: val_loss did not improve from 0.20194\n",
      "115/115 [==============================] - 4852s 42s/step - loss: 0.1181 - dice_coef: 0.8819 - val_loss: 0.2282 - val_dice_coef: 0.7709 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1134 - dice_coef: 0.8866 \n",
      "Epoch 22: val_loss improved from 0.20194 to 0.19848, saving model to files\\model_segmentation_256px.h5\n",
      "115/115 [==============================] - 4848s 42s/step - loss: 0.1134 - dice_coef: 0.8866 - val_loss: 0.1985 - val_dice_coef: 0.8033 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1055 - dice_coef: 0.8945 \n",
      "Epoch 23: val_loss improved from 0.19848 to 0.19363, saving model to files\\model_segmentation_256px.h5\n",
      "115/115 [==============================] - 4850s 42s/step - loss: 0.1055 - dice_coef: 0.8945 - val_loss: 0.1936 - val_dice_coef: 0.8056 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0983 - dice_coef: 0.9017 \n",
      "Epoch 24: val_loss did not improve from 0.19363\n",
      "115/115 [==============================] - 4848s 42s/step - loss: 0.0983 - dice_coef: 0.9017 - val_loss: 0.1986 - val_dice_coef: 0.8001 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0959 - dice_coef: 0.9041 \n",
      "Epoch 25: val_loss did not improve from 0.19363\n",
      "115/115 [==============================] - 4859s 42s/step - loss: 0.0959 - dice_coef: 0.9041 - val_loss: 0.2071 - val_dice_coef: 0.7917 - lr: 1.0000e-04\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - ETA: 0s - loss: 0.0941 - dice_coef: 0.9059 \n",
      "Epoch 26: val_loss did not improve from 0.19363\n",
      "115/115 [==============================] - 4869s 42s/step - loss: 0.0941 - dice_coef: 0.9059 - val_loss: 0.2175 - val_dice_coef: 0.7818 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0942 - dice_coef: 0.9058 \n",
      "Epoch 27: val_loss did not improve from 0.19363\n",
      "115/115 [==============================] - 4868s 42s/step - loss: 0.0942 - dice_coef: 0.9058 - val_loss: 0.1948 - val_dice_coef: 0.8034 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0877 - dice_coef: 0.9123 \n",
      "Epoch 28: val_loss did not improve from 0.19363\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "115/115 [==============================] - 4863s 42s/step - loss: 0.0877 - dice_coef: 0.9123 - val_loss: 0.1953 - val_dice_coef: 0.8014 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0807 - dice_coef: 0.9193 \n",
      "Epoch 29: val_loss improved from 0.19363 to 0.17950, saving model to files\\model_segmentation_256px.h5\n",
      "115/115 [==============================] - 4888s 43s/step - loss: 0.0807 - dice_coef: 0.9193 - val_loss: 0.1795 - val_dice_coef: 0.8185 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0749 - dice_coef: 0.9251 \n",
      "Epoch 30: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4857s 42s/step - loss: 0.0749 - dice_coef: 0.9251 - val_loss: 0.1797 - val_dice_coef: 0.8182 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0727 - dice_coef: 0.9273 \n",
      "Epoch 31: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4882s 42s/step - loss: 0.0727 - dice_coef: 0.9273 - val_loss: 0.1801 - val_dice_coef: 0.8180 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0709 - dice_coef: 0.9291 \n",
      "Epoch 32: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4887s 43s/step - loss: 0.0709 - dice_coef: 0.9291 - val_loss: 0.1808 - val_dice_coef: 0.8174 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0695 - dice_coef: 0.9305 \n",
      "Epoch 33: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4888s 43s/step - loss: 0.0695 - dice_coef: 0.9305 - val_loss: 0.1815 - val_dice_coef: 0.8167 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0681 - dice_coef: 0.9319 \n",
      "Epoch 34: val_loss did not improve from 0.17950\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "115/115 [==============================] - 4881s 42s/step - loss: 0.0681 - dice_coef: 0.9319 - val_loss: 0.1820 - val_dice_coef: 0.8162 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0669 - dice_coef: 0.9331 \n",
      "Epoch 35: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4891s 43s/step - loss: 0.0669 - dice_coef: 0.9331 - val_loss: 0.1832 - val_dice_coef: 0.8148 - lr: 1.0000e-06\n",
      "Epoch 36/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0665 - dice_coef: 0.9335 \n",
      "Epoch 36: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4894s 43s/step - loss: 0.0665 - dice_coef: 0.9335 - val_loss: 0.1828 - val_dice_coef: 0.8151 - lr: 1.0000e-06\n",
      "Epoch 37/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0663 - dice_coef: 0.9337 \n",
      "Epoch 37: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4874s 42s/step - loss: 0.0663 - dice_coef: 0.9337 - val_loss: 0.1828 - val_dice_coef: 0.8152 - lr: 1.0000e-06\n",
      "Epoch 38/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0661 - dice_coef: 0.9339 \n",
      "Epoch 38: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4871s 42s/step - loss: 0.0661 - dice_coef: 0.9339 - val_loss: 0.1829 - val_dice_coef: 0.8151 - lr: 1.0000e-06\n",
      "Epoch 39/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0659 - dice_coef: 0.9341 \n",
      "Epoch 39: val_loss did not improve from 0.17950\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "115/115 [==============================] - 4881s 42s/step - loss: 0.0659 - dice_coef: 0.9341 - val_loss: 0.1830 - val_dice_coef: 0.8150 - lr: 1.0000e-06\n",
      "Epoch 40/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0657 - dice_coef: 0.9343 \n",
      "Epoch 40: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4872s 42s/step - loss: 0.0657 - dice_coef: 0.9343 - val_loss: 0.1828 - val_dice_coef: 0.8152 - lr: 1.0000e-07\n",
      "Epoch 41/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0656 - dice_coef: 0.9344 \n",
      "Epoch 41: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4873s 42s/step - loss: 0.0656 - dice_coef: 0.9344 - val_loss: 0.1827 - val_dice_coef: 0.8154 - lr: 1.0000e-07\n",
      "Epoch 42/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0656 - dice_coef: 0.9344 \n",
      "Epoch 42: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4877s 42s/step - loss: 0.0656 - dice_coef: 0.9344 - val_loss: 0.1826 - val_dice_coef: 0.8154 - lr: 1.0000e-07\n",
      "Epoch 43/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0656 - dice_coef: 0.9344 \n",
      "Epoch 43: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4882s 42s/step - loss: 0.0656 - dice_coef: 0.9344 - val_loss: 0.1826 - val_dice_coef: 0.8155 - lr: 1.0000e-07\n",
      "Epoch 44/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0656 - dice_coef: 0.9344 \n",
      "Epoch 44: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4874s 42s/step - loss: 0.0656 - dice_coef: 0.9344 - val_loss: 0.1825 - val_dice_coef: 0.8155 - lr: 1.0000e-07\n",
      "Epoch 45/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0655 - dice_coef: 0.9345 \n",
      "Epoch 45: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4871s 42s/step - loss: 0.0655 - dice_coef: 0.9345 - val_loss: 0.1825 - val_dice_coef: 0.8155 - lr: 1.0000e-07\n",
      "Epoch 46/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0655 - dice_coef: 0.9345 \n",
      "Epoch 46: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4915s 43s/step - loss: 0.0655 - dice_coef: 0.9345 - val_loss: 0.1825 - val_dice_coef: 0.8155 - lr: 1.0000e-07\n",
      "Epoch 47/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0655 - dice_coef: 0.9345 \n",
      "Epoch 47: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4889s 43s/step - loss: 0.0655 - dice_coef: 0.9345 - val_loss: 0.1825 - val_dice_coef: 0.8155 - lr: 1.0000e-07\n",
      "Epoch 48/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0655 - dice_coef: 0.9345 \n",
      "Epoch 48: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4888s 43s/step - loss: 0.0655 - dice_coef: 0.9345 - val_loss: 0.1825 - val_dice_coef: 0.8155 - lr: 1.0000e-07\n",
      "Epoch 49/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0655 - dice_coef: 0.9345 \n",
      "Epoch 49: val_loss did not improve from 0.17950\n",
      "115/115 [==============================] - 4884s 42s/step - loss: 0.0655 - dice_coef: 0.9345 - val_loss: 0.1825 - val_dice_coef: 0.8155 - lr: 1.0000e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26e95763160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd15cdd",
   "metadata": {},
   "source": [
    "#  Directory for Results files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae86026f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:08:32.493958Z",
     "start_time": "2023-12-10T16:08:32.462698Z"
    }
   },
   "outputs": [],
   "source": [
    "create_dir(\"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5a00d8",
   "metadata": {},
   "source": [
    "# load model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78c08661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:08:35.125540Z",
     "start_time": "2023-12-10T16:08:32.493958Z"
    }
   },
   "outputs": [],
   "source": [
    "with CustomObjectScope({\"dice_coef\": dice_coef, \"dice_loss\": dice_loss}):\n",
    "    model = tf.keras.models.load_model(os.path.join(\"files\", model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ed15d",
   "metadata": {},
   "source": [
    "# Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af480a8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:17:13.174002Z",
     "start_time": "2023-12-10T16:08:35.125540Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 612/612 [08:38<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "SCORE = []\n",
    "for x, y in tqdm(zip(test_x, test_y), total=len(test_y)):\n",
    "    \"\"\" Extracting the name \"\"\"\n",
    "    name = x.split(\"/\")[-1]\n",
    "\n",
    "    \"\"\" Reading the image \"\"\"\n",
    "    image = cv2.imread(x, cv2.IMREAD_COLOR) ## [H, w, 3]\n",
    "    image = cv2.resize(image, (W, H))       ## [H, w, 3]\n",
    "    x = image/255.0                         ## [H, w, 3]\n",
    "    x = np.expand_dims(x, axis=0)           ## [1, H, w, 3]\n",
    "\n",
    "    \"\"\" Reading the mask \"\"\"\n",
    "    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (W, H))\n",
    "\n",
    "    \"\"\" Prediction \"\"\"\n",
    "    y_pred = model.predict(x, verbose=0)[0]\n",
    "    y_pred = np.squeeze(y_pred, axis=-1)\n",
    "    y_pred = y_pred >= 0.5\n",
    "    y_pred = y_pred.astype(np.int32)\n",
    "\n",
    "    \"\"\" Saving the prediction \"\"\"\n",
    "    save_image_path = os.path.join(\"results\", name)\n",
    "    save_results(image, mask, y_pred, save_image_path)\n",
    "\n",
    "    \"\"\" Flatten the array \"\"\"\n",
    "    mask = mask/255.0\n",
    "    mask = (mask > 0.5).astype(np.int32).flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "\n",
    "    \"\"\" Calculating the metrics values \"\"\"\n",
    "    f1_value = f1_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n",
    "    jac_value = jaccard_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n",
    "    recall_value = recall_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n",
    "    precision_value = precision_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n",
    "    SCORE.append([name, f1_value, jac_value, recall_value, precision_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b7ecb09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:17:13.218098Z",
     "start_time": "2023-12-10T16:17:13.174002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.76724\n",
      "Jaccard: 0.67986\n",
      "Recall: 0.76924\n",
      "Precision: 0.81618\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Metrics values \"\"\"\n",
    "score = [s[1:]for s in SCORE]\n",
    "score = np.mean(score, axis=0)\n",
    "print(f\"F1: {score[0]:0.5f}\")\n",
    "print(f\"Jaccard: {score[1]:0.5f}\")\n",
    "print(f\"Recall: {score[2]:0.5f}\")\n",
    "print(f\"Precision: {score[3]:0.5f}\")\n",
    "\n",
    "df = pd.DataFrame(SCORE, columns=[\"Image\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n",
    "df.to_csv(\"files/score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6699b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "253.594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
